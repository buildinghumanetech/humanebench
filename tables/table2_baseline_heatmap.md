# Table 2: Baseline Performance Heatmap

Per-principle and overall humaneness scores for all 13 models in baseline condition.

| Model                   |   HumaneScore |   Respect Attention |   Enable Choices |   Enhance Capabilities |   Protect Safety |   Foster Relationships |   Long-term Wellbeing |   Be Transparent |   Equity & Inclusion |
|:------------------------|--------------:|--------------------:|-----------------:|-----------------------:|-----------------:|-----------------------:|----------------------:|-----------------:|---------------------:|
| claude-opus-4.1         |          0.68 |               -0.04 |             0.75 |                   0.94 |             0.81 |                   0.85 |                  0.92 |             0.39 |                 0.83 |
| claude-sonnet-4         |          0.69 |               -0.06 |             0.77 |                   0.92 |             0.8  |                   0.92 |                  0.95 |             0.4  |                 0.81 |
| claude-sonnet-4.5       |          0.75 |                0.26 |             0.77 |                   0.92 |             0.79 |                   0.88 |                  0.95 |             0.65 |                 0.81 |
| deepseek-v3.1-terminus  |          0.75 |               -0.03 |             0.82 |                   0.98 |             0.91 |                   0.91 |                  0.98 |             0.59 |                 0.86 |
| gemini-2.0-flash-001    |          0.75 |               -0.04 |             0.88 |                   0.97 |             0.91 |                   0.91 |                  0.99 |             0.59 |                 0.76 |
| gemini-2.5-flash        |          0.72 |               -0.11 |             0.84 |                   0.97 |             0.91 |                   0.92 |                  0.96 |             0.5  |                 0.78 |
| gemini-2.5-pro          |          0.77 |               -0.01 |             0.82 |                   0.96 |             0.92 |                   0.92 |                  0.98 |             0.66 |                 0.87 |
| gemini-3-pro-preview    |          0.78 |                0.14 |             0.83 |                   0.97 |             0.89 |                   0.95 |                  0.97 |             0.68 |                 0.84 |
| gpt-4.1                 |          0.67 |               -0.2  |             0.77 |                   0.82 |             0.86 |                   0.86 |                  0.94 |             0.49 |                 0.8  |
| gpt-4o-2024-11-20       |          0.68 |                0.03 |             0.73 |                   0.81 |             0.81 |                   0.86 |                  0.92 |             0.51 |                 0.75 |
| gpt-5                   |          0.86 |                0.35 |             0.94 |                   0.96 |             0.97 |                   0.94 |                  0.99 |             0.79 |                 0.94 |
| gpt-5.1                 |          0.86 |                0.28 |             0.96 |                   0.97 |             0.97 |                   0.94 |                  0.99 |             0.85 |                 0.94 |
| grok-4                  |          0.69 |               -0.38 |             0.83 |                   0.93 |             0.94 |                   0.89 |                  0.95 |             0.54 |                 0.79 |
| llama-3.1-405b-instruct |          0.56 |               -0.06 |             0.51 |                   0.79 |             0.55 |                   0.89 |                  0.8  |             0.29 |                 0.7  |
| llama-4-maverick        |          0.59 |               -0.11 |             0.6  |                   0.82 |             0.68 |                   0.85 |                  0.85 |             0.38 |                 0.65 |